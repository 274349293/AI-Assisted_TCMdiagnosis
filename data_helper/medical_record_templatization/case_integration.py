import pandas as pd
import numpy as np
from pathlib import Path
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

"""
åˆå¹¶å‹æ¨å’Œå–œæ°çš„é—¨è¯Šç—…å†ï¼Œå¯¹é—¨è¯Šç—…å†è¿›è¡Œç­›é€‰

åˆå¹¶æ•°æ®æºï¼š
"../data/case_data/å‹æ¨0725+.xlsx",
"../data/case_data/å–œæ°0725+.xlsx"

è¾“å‡º2ä¸ªæ–‡ä»¶ï¼š
1. è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•
2. è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•
"""


def load_and_merge_medical_records():
    """
    åŠ è½½ä¸¤ä¸ªç—…å†Excelæ–‡ä»¶å¹¶åˆå¹¶æ•°æ®

    Returns:
        pd.DataFrame: åˆå¹¶åçš„ç—…å†æ•°æ®
    """
    logger.info("å¼€å§‹åŠ è½½ç—…å†æ•°æ®æ–‡ä»¶...")

    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    file_paths = [
        "../data/case_data/å‹æ¨0725+.xlsx",
        "../data/case_data/å–œæ°0725+.xlsx"
    ]

    # å­˜å‚¨æ‰€æœ‰æ•°æ®çš„åˆ—è¡¨
    all_records = []

    for file_path in file_paths:
        try:
            logger.info(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")

            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(file_path, engine='openpyxl')
            logger.info(f"æˆåŠŸè¯»å–æ–‡ä»¶ {file_path}ï¼ŒåŒ…å« {len(df)} æ¡è®°å½•")

            # æ·»åŠ æ•°æ®æ¥æºæ ‡è¯†
            df['æ•°æ®æ¥æº'] = file_path
            all_records.append(df)

        except FileNotFoundError:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    if all_records:
        combined_df = pd.concat(all_records, ignore_index=True)
        logger.info(f"æ•°æ®åˆå¹¶å®Œæˆï¼Œæ€»è®¡ {len(combined_df)} æ¡ç—…å†è®°å½•")
        return combined_df
    else:
        logger.error("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")
        return pd.DataFrame()


def analyze_data_completeness(df):
    """
    åˆ†ææ•°æ®å®Œæ•´æ€§å¹¶åˆ†ç±»

    Args:
        df (pd.DataFrame): ç—…å†æ•°æ®

    Returns:
        tuple: (è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•, è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•, åˆ†æç»“æœ)
    """
    logger.info("å¼€å§‹åˆ†ææ•°æ®å®Œæ•´æ€§...")

    # å®šä¹‰å…³é”®åŒ»ç–—å­—æ®µ
    key_fields = [
        'ä¸»è¯‰',  # æ‚£è€…ä¸»è¦ç—‡çŠ¶æè¿°
        'ç°ç—…å²',  # ç°åœ¨ç–¾ç—…çš„ç—…å²
        'æ—¢å¾€å²',  # è¿‡å»çš„ç–¾ç—…å²
        'è¾…åŠ©æ£€æŸ¥',  # å„ç§æ£€æŸ¥ç»“æœ
        'PE/æ£€æŸ¥',  # ä½“æ ¼æ£€æŸ¥ç»“æœ
        'ç—…æœº',  # ä¸­åŒ»ç—…æœºåˆ†æ
        'æ²»åˆ™/å¤„ç†',  # æ²»ç–—åŸåˆ™
        'åŒ»å˜±'  # åŒ»ç”Ÿçš„å¤„æ–¹å’Œå»ºè®®
    ]

    def is_empty_value(value):
        """åˆ¤æ–­å€¼æ˜¯å¦ä¸ºç©º"""
        if pd.isna(value):
            return True
        if isinstance(value, str) and value.strip() == '':
            return True
        return False

    # è®¡ç®—æ¯æ¡è®°å½•çš„ç¼ºå¤±å­—æ®µæ•°
    missing_counts = []
    for _, row in df.iterrows():
        missing_count = sum(1 for field in key_fields
                            if field in df.columns and is_empty_value(row[field]))
        missing_counts.append(missing_count)

    df['ç¼ºå¤±å­—æ®µæ•°é‡'] = missing_counts
    df['æ€»å…³é”®å­—æ®µæ•°'] = len([f for f in key_fields if f in df.columns])
    df['æ•°æ®å®Œæ•´æ€§ç™¾åˆ†æ¯”'] = ((df['æ€»å…³é”®å­—æ®µæ•°'] - df['ç¼ºå¤±å­—æ®µæ•°é‡']) / df['æ€»å…³é”®å­—æ®µæ•°'] * 100).round(2)

    # åˆ†ç±»æ•°æ®
    # ç¬¬ä¸€ç±»ï¼šè‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•
    incomplete_records = df[df['ç¼ºå¤±å­—æ®µæ•°é‡'] > 0].copy()

    # ç¬¬äºŒç±»ï¼šè‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•
    complete_records = df[df['ç¼ºå¤±å­—æ®µæ•°é‡'] < len([f for f in key_fields if f in df.columns])].copy()

    # ç»Ÿè®¡åˆ†æç»“æœ
    analysis_results = {
        'æ€»è®°å½•æ•°': len(df),
        'è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•æ•°': len(incomplete_records),
        'è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•æ•°': len(complete_records),
        'å­—æ®µå¡«å……ç‡': {}
    }

    # è®¡ç®—å„å­—æ®µå¡«å……ç‡
    for field in key_fields:
        if field in df.columns:
            empty_count = df[field].apply(is_empty_value).sum()
            fill_rate = ((len(df) - empty_count) / len(df)) * 100
            analysis_results['å­—æ®µå¡«å……ç‡'][field] = round(fill_rate, 2)

    # æŒ‰æ•°æ®æ¥æºç»Ÿè®¡
    if 'æ•°æ®æ¥æº' in df.columns:
        analysis_results['æ•°æ®æ¥æºç»Ÿè®¡'] = {}
        for source in df['æ•°æ®æ¥æº'].unique():
            source_df = df[df['æ•°æ®æ¥æº'] == source]
            at_least_one_empty = len(source_df[source_df['ç¼ºå¤±å­—æ®µæ•°é‡'] > 0])
            at_least_one_data = len(
                source_df[source_df['ç¼ºå¤±å­—æ®µæ•°é‡'] < len([f for f in key_fields if f in df.columns])])
            analysis_results['æ•°æ®æ¥æºç»Ÿè®¡'][source] = {
                'æ€»è®°å½•æ•°': len(source_df),
                'è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©º': at_least_one_empty,
                'è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®': at_least_one_data
            }

    return incomplete_records, complete_records, analysis_results


def print_analysis_results(analysis_results):
    """
    æ‰“å°æ•°æ®åˆ†æç»“æœ

    Args:
        analysis_results (dict): åˆ†æç»“æœ
    """
    logger.info("=" * 80)
    logger.info("ç—…å†æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š")
    logger.info("=" * 80)

    # åŸºæœ¬ç»Ÿè®¡
    logger.info("ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    logger.info(f"   æ€»è®°å½•æ•°: {analysis_results['æ€»è®°å½•æ•°']} æ¡")
    logger.info(f"   è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•æ•°: {analysis_results['è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•æ•°']} æ¡")
    logger.info(f"   è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•æ•°: {analysis_results['è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•æ•°']} æ¡")

    # å­—æ®µå¡«å……ç‡
    logger.info("")
    logger.info("ğŸ“‹ å„å­—æ®µå¡«å……ç‡:")
    field_stats = analysis_results['å­—æ®µå¡«å……ç‡']
    sorted_fields = sorted(field_stats.items(), key=lambda x: x[1], reverse=True)
    for i, (field, rate) in enumerate(sorted_fields, 1):
        logger.info(f"   {i}. {field}: {rate}%")

    # æ•°æ®æ¥æºå¯¹æ¯”
    if 'æ•°æ®æ¥æºç»Ÿè®¡' in analysis_results:
        logger.info("")
        logger.info("ğŸ“Š æ•°æ®æ¥æºè´¨é‡å¯¹æ¯”:")
        for source, stats in analysis_results['æ•°æ®æ¥æºç»Ÿè®¡'].items():
            logger.info(f"   {source}:")
            logger.info(f"     æ€»è®°å½•æ•°: {stats['æ€»è®°å½•æ•°']} æ¡")
            logger.info(f"     è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©º: {stats['è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©º']} æ¡")
            logger.info(f"     è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®: {stats['è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®']} æ¡")

    logger.info("=" * 80)


def save_results(incomplete_records, complete_records):
    """
    ä¿å­˜åˆ†ç±»ç»“æœåˆ°Excelæ–‡ä»¶

    Args:
        incomplete_records (pd.DataFrame): è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•
        complete_records (pd.DataFrame): è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•
    """
    logger.info("å¼€å§‹ä¿å­˜åˆ†ç±»ç»“æœ...")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ä¿å­˜è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•
    if len(incomplete_records) > 0:
        incomplete_file = f"../data/case_data/ç—…å†æ•°æ®_å¾…è¡¥å……_{timestamp}.xlsx"
        incomplete_records.to_excel(incomplete_file, index=False)
        logger.info(f"âœ… è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©ºçš„è®°å½•å·²ä¿å­˜: {incomplete_file}")

    # ä¿å­˜è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•
    if len(complete_records) > 0:
        complete_file = f"../data/case_data/ç—…å†æ•°æ®_å¯ä½¿ç”¨_{timestamp}.xlsx"
        complete_records.to_excel(complete_file, index=False)
        logger.info(f"âœ… è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®çš„è®°å½•å·²ä¿å­˜: {complete_file}")


def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®æ¸…æ´—æµç¨‹
    """
    logger.info("=" * 80)
    logger.info("å¼€å§‹æ‰§è¡Œç—…å†æ•°æ®æ¸…æ´—ä»»åŠ¡")
    logger.info("=" * 80)

    try:
        # æ­¥éª¤1ï¼šåŠ è½½å’Œåˆå¹¶æ•°æ®
        logger.info("ğŸ”„ æ­¥éª¤ 1/4: åŠ è½½å’Œåˆå¹¶ç—…å†æ•°æ®")
        combined_data = load_and_merge_medical_records()

        if combined_data.empty:
            logger.error("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢")
            return

        # æ­¥éª¤2ï¼šåˆ†ææ•°æ®å®Œæ•´æ€§å¹¶åˆ†ç±»
        logger.info("ğŸ”„ æ­¥éª¤ 2/4: åˆ†ææ•°æ®å®Œæ•´æ€§å¹¶åˆ†ç±»")
        incomplete_records, complete_records, analysis_results = analyze_data_completeness(combined_data)

        # æ­¥éª¤3ï¼šæ‰“å°åˆ†æç»“æœ
        logger.info("ğŸ”„ æ­¥éª¤ 3/4: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        print_analysis_results(analysis_results)

        # æ­¥éª¤4ï¼šä¿å­˜åˆ†ç±»ç»“æœ
        logger.info("ğŸ”„ æ­¥éª¤ 4/4: ä¿å­˜åˆ†ç±»ç»“æœ")
        save_results(incomplete_records, complete_records)

        logger.info("=" * 80)
        logger.info("âœ… ç—…å†æ•°æ®æ¸…æ´—ä»»åŠ¡å®Œæˆ!")
        logger.info("=" * 80)
        logger.info("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        logger.info(f"   â”œâ”€â”€ ç—…å†æ•°æ®_è‡³å°‘ä¸€ä¸ªå­—æ®µä¸ºç©º_[æ—¶é—´æˆ³].xlsx ({len(incomplete_records)}æ¡è®°å½•)")
        logger.info(f"   â””â”€â”€ ç—…å†æ•°æ®_è‡³å°‘ä¸€ä¸ªå­—æ®µæœ‰æ•°æ®_[æ—¶é—´æˆ³].xlsx ({len(complete_records)}æ¡è®°å½•)")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        raise


if __name__ == "__main__":
    main()
